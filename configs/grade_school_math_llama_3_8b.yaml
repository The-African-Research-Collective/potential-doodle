# =============================================================================
# ========================= Model Arguments ===================================
# =============================================================================
model_name_or_path: "meta-llama/Llama-3.1-8B-Instruct"
model_revision: main
# =============================================================================
# ========================= Data Arguments ===================================
# =============================================================================
dataset_name: taresco/doodle_ift_math_10k
chat_template_name: llama_3_instruct
max_seq_length: 2048
# =============================================================================
# ========================= Experiments Arguments =============================
# =============================================================================
exp_name: persona_math_10k_llama_3_8b
run_name: persona_math_10k_llama_3_8b
project_name: persona_math_10k_llama_3_8b
seed: 42
report_to:
  - wandb
gradient_accumulation_steps: 16
use_flash_attention: True
output_dir: /home/oogundep/runs
per_device_train_batch_size: 1
push_to_hub: true
with_tracking: true
hf_entity: taresco
reduce_loss: sum
report_to: wandb
wandb_project_name: potential-doodle
wandb_entity: african-research-collective
logging_steps: 1
checkpointing_steps: epoch
hf_repo_id: persona_math_10k_llama_3_8b

