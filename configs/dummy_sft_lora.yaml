# =============================================================================
# ========================= Model Arguments ===================================
# =============================================================================
model_name_or_path: meta-llama/Llama-3.2-1B
model_revision: main
use_lora: True
# =============================================================================
# ========================= Data Arguments ===================================
# =============================================================================
dataset_name: allenai/tulu-3-sft-personas-instruction-following
chat_template_name: llama_3_instruct
max_train_samples: 1000
max_seq_length: 1024
# =============================================================================
# ========================= Experiments Arguments =============================
# =============================================================================
exp_name: dummy_lora
run_name: dummy_lora
project_name: dummy_lora
seed: 42
report_to:
  - wandb
gradient_accumulation_steps: 1
use_flash_attention: False
output_dir: runs
per_device_train_batch_size: 1
checkpointing_steps: epoch
push_to_hub: true
with_tracking: true
hf_entity: taresco
reduce_loss: sum
report_to: wandb
wandb_project_name: potential-doodle
wandb_entity: african-research-collective
logging_steps: 10
save_steps: 100
